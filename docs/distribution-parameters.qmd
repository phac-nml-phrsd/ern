---
title: "Estimating parameters for various distributions induced by SARS-CoV-2 Omicron"
author: "Irena Papst"
format:
  html:
      embed-resources: true
editor: visual
---

```{r setup, echo=FALSE}
library(glue)
library(tibble)
```

[Jump to parameter values](#sec-params-gen-int "Fitted parameter values")

## Motivation

In order to calculate Rt from clinical reports or wastewater concentation, we need to assume a few things, including a generation interval distribution. For clinical reports, we additionally need an incubation time distribution. For COVID-19 in Canada, the most relevant parameter estimates come from analyzing Omicron infection data as the majority of lineages circulating in the country since January 2021 have been descendants of Omicron.

Daniel Park suggested using [Manica *et al.* 2022](https://www.sciencedirect.com/science/article/pii/S2666776222001405) to get parameter estimates these distributions as the data is specifically Omicron-based. This paper also gives a measure of uncertainty around each parameter estimate.

We want a measure of uncertainty around each distribution parameter because we want to propagate uncertainty in the specification of these distributions through to the $R_t$ calculation. We will start with distribution parameters along with uncertainty around each parameter and use these givens to parameterize a *family* of distributions. Then we calculate $R_t$ using an ensemble, where for each realization we draw from the specified familes of distributions to select one generation interval distribution (and one incubation period in the case of clinical data) to use for that specific calculation.

Note that Manica *et al.* estimate distributions for two different generation times but we will use the **intrinsic generation time**.

## The catch

Currently in the `ern` package, we have infrastructure to calculate $R_t$ with a family of distributions as described above, where the family is specified by:

-   a distribution type (*e.g.* Gamma, log-normal)

-   a distribution mean

-   a standard deviation about that mean

-   a distribution standard deviation

-   a standard deviation about that standard deviation

However, in the Manica *et al.* paper, they give their distribution parameter estimates as follows:

![](figs/manica-table2.png){fig-align="center"}

Here we have estimates for the mean, shape, and scale parameters of each family of distributions. Of course, knowing at least two of these, we can specify a family of Gammas without a standard deviation---that's not the problem. The problem is that **the uncertainty in each estimated parameter is reported in terms of a credible interval**, *i.e.* in a non-parametric way. We need a parameteric approach to draw from the associated family of distributions for each realization of our $R_t$ calculation.

These credible intervals emerge as a summary of the Bayesian posterior distribution of each parameter. However, I didn't find any information in the paper (or its appendices) that would help identify the appropriate functional form for these distributions...

## Ben & dC to the rescue

I talked to Ben Bolker about this problem and he pointed out:

> Bayesian posterior distributions do not generally have known/assumed functional forms; they emerge from the forms chosen for the likelihood and the priors (\*if\* one chooses a conjugate prior then the form of the posterior is analytically tractable \-- otherwise it's just whatever comes out of the sampler).

Ben suggested something that David Champredon had described to me earlier in general terms: assume each distribution parameter is itself Gamma distributed (or log-normal, or another continuous distribution with non-negative support since these parameters must be non-negative). Then, assume the credible interval bounds give quantiles of this distribution and use them, along with a mean (equal to the mean estimate of the focal parameter) to fit a Gamma distribution.

However, for each Gamma family of distributions, we need to fit distributions over **two** parameters to specify it. Ben suggested doing two independent one-dimensional optimizations to fit distributions for mean and the shape for each family. According to Ben, for the Gamma, the shape and scale are often more strongly correlated than the mean and shape, hence why we should choose the latter pair for two independent one-dimensional optimizations. Alternatively, one should instead perform a two-dimensional optimization over shape and scale simultaneously, but that could be tricky.

## The method

For each distribution parameter we're trying to fit (*e.g.*, generation interval mean and generation interval shape), we have the mean and 95% credible interval bounds. Fix the mean as if it's the truth, and optimize over the unknown shape parameter. Once we have that in hand we can derive a standard deviation for the unknown distribution parameter.

## The doing

Here is some sample code courtesy of Ben to accomplish the optimization task as described above:

```{r optim_base}
#| results: hold
score_fun <- function(s, m = 3.49, ci_target = c(3.17, 3.77)) {
  # define gamma parameters
  shape <- s
  scale <- m/s
  # get quantiles
  ci <- qgamma(c(0.025, 0.975), shape = shape, scale = scale)
  # calculate sum of square differences as a score
  return(sum((ci-ci_target)^2))
}

opt_out <- optim(
  # initial value for shape
  par = 1, 
  # scoring function
  fn = score_fun,
  # bounds on shape
  lower = 0.0001, upper = 1000,
  method = "Brent"
)

shape_best <- opt_out$par
sd_best <- 3.49/sqrt(shape_best)

print(glue("fitted sd: {round(sd_best, 4)}"))
print(glue("min sum of squared diffs: {round(opt_out$value, 6)}"))
```

In the code above, we use the following little calculation to derive the formula for the standard deviation, $\sigma$, of a Gamma distribution given the mean, $\mu$, and shape parameter, $\alpha$ (via the scale parameter, $\beta$):

$$
\begin{align}
\mu = \alpha\beta&, \quad \sigma^2 = \alpha\beta^2 \\ \\
\beta &= \mu/\alpha \\
\sigma^2 &= \alpha\beta^2 \\
&= \alpha(\mu/\alpha)^2 \\
&= \alpha\mu^2/\alpha^2 \\
&=\mu^2/\alpha \\ \\
\sigma &= \mu/\sqrt{\alpha}
\end{align}
$$

We'll encode this formula in a function for later use:

```{r shape_to_sd}
shape_to_sd <- function(shape, mean) mean/sqrt(shape)
```

Let's wrap all of this in another function where we specify the mean and credible interval bounds and get out the standard deviation:

```{r optim_wrapped}
make_score_fun <- function(){
  
  score_fun <- function(s, m, ci_target) {
    shape <- s
    scale <- m/s
    ci <- qgamma(c(0.025, 0.975), shape = shape, scale = scale)
    return(sum((ci-ci_target)^2))
  }
  
  return(score_fun)
}

fit_sd <- function(mean, ci){
  score_fun <- make_score_fun()

  opt_out <- optim(
    par = 1, 
    fn = score_fun,
    m = mean,
    ci_target = ci,
    lower = 0.0001, upper = 1000,
    method = "Brent"
  )
  
  # get best shape parameter found and return standard deviation
  shape_best <- opt_out$par
  sd_best <- shape_to_sd(shape_best, mean)
  
  return(list(
    sd = sd_best,
    score = opt_out$value
  ))
}
```

Let's make sure we get the same fitted parameter (and score) as in the base code above using our wrapped function:

```{r optim_wrapped_test}
print_fit_sd <- function(mean, ci){
  fit <- fit_sd(mean, ci)
  print(glue("fitted sd: {round(fit$sd, 4)}"))
  print(glue("min sum of squared diffs: {round(fit$score, 6)}"))
}

print_fit_sd(mean = 3.49, ci = c(3.17, 3.77))
```

Looks good!

## Fitted parameter values {#sec-params}

Finally we have summaries of the fitted parameter values using the code above for each family of distributions!

```{r make_fit_table}
#' Make table summarizing parameters for each family of distributions
#'
#' @param mean.inputs list with elements `mean` (scalar) and `ci` (numeric vector of length 2) 
#' @param shape.inputs same format as `mean.inputs`
#'
#' @return tibble 
make_summary_table <- function(mean.inputs, shape.inputs){

  fit.mean <- fit_sd(mean = mean.inputs$mean, ci = mean.inputs$ci)
  fit.shape <- fit_sd(mean = shape.inputs$mean, ci = shape.inputs$ci)
  
  tb <- tribble(
    ~parameter,           ~`value type`,                 ~`value`,
    "distribution mean",  "mean (assumed)",              mean.inputs$mean,
    "",                   "standard deviation (fitted)", fit.mean$sd,
    "",                   "fit score",                   fit.mean$score,
    "distribution shape", "mean (assumed)",              shape.inputs$mean,
    "",                   "standard deviation (fitted)", fit.shape$sd,
    "",                   "fit score",                   fit.shape$score
  )
}
```

### Generation interval {#sec-params-gen-int}

```{r summary_gen_int, echo = FALSE}
summary.gen.int <- make_summary_table(
  mean.inputs = list(
    mean = 6.84,
    ci = c(5.72, 8.60)
  ),
  shape.inputs = list(
    mean = 2.39,
    ci = c(2.01, 3.34)
  )
)

knitr::kable(summary.gen.int, digits = 4)
```

### Incubation period

```{r summary_inc_per, echo = FALSE}
summary.inc.per <- make_summary_table(
  mean.inputs = list(
    mean = 3.49,
    ci = c(3.19, 3.77)
  ),
  shape.inputs = list(
    mean = 8.50,
    ci = c(6.14, 13.20)
  )
)

knitr::kable(summary.inc.per, digits = 4)
```
